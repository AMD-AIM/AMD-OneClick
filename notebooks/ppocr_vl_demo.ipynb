{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ” PaddleOCR-VL Demo on AMD GPU\n",
        "\n",
        "This notebook demonstrates how to use **PaddleOCR-VL** (Vision-Language OCR) model running on AMD GPU with vLLM backend.\n",
        "\n",
        "## Features\n",
        "- **Layout Detection**: Detect document structure (text, images, tables, titles)\n",
        "- **VL Recognition**: Vision-Language model for accurate text recognition\n",
        "- **vLLM Backend**: High-performance inference on AMD GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Check vLLM Server Status\n",
        "\n",
        "First, let's verify that the vLLM server is running and ready.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Check vLLM server status\n",
        "try:\n",
        "    response = requests.get(\"http://localhost:8118/v1/models\")\n",
        "    models = response.json()\n",
        "    print(\"âœ… vLLM Server is running!\")\n",
        "    print(f\"Available models: {[m['id'] for m in models['data']]}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ vLLM Server not ready: {e}\")\n",
        "    print(\"Please wait a moment and retry...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load PaddleOCR-VL Pipeline\n",
        "\n",
        "Load the PaddleOCR-VL pipeline with vLLM backend configuration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/opt/PaddleX\")\n",
        "\n",
        "# Set environment variable to skip model source check\n",
        "os.environ[\"PADDLE_PDX_DISABLE_MODEL_SOURCE_CHECK\"] = \"True\"\n",
        "\n",
        "from paddlex import create_pipeline\n",
        "\n",
        "# Create the PaddleOCR-VL pipeline with vLLM backend\n",
        "pipeline = create_pipeline(pipeline=\"PaddleOCR-VL-vllm.yaml\")\n",
        "print(\"âœ… Pipeline loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Display Test Image\n",
        "\n",
        "Let's view the demo image before running OCR.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display the test image\n",
        "test_image = \"/opt/PaddleX/test/paddleocr_vl_demo.png\"\n",
        "print(f\"Test image: {test_image}\")\n",
        "display(Image(filename=test_image, width=600))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run OCR Inference\n",
        "\n",
        "Execute the PaddleOCR-VL pipeline on the test image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# Run inference\n",
        "result = pipeline.predict(test_image)\n",
        "\n",
        "print(\"âœ… Inference completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. View Results\n",
        "\n",
        "Display the extracted text content from the document.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process and display results\n",
        "for res in result:\n",
        "    # Get parsing results - res is a PaddleOCRVLResult (dict-like)\n",
        "    parsing_list = res.get('parsing_res_list', [])\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸ“„ EXTRACTED CONTENT\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for i, block in enumerate(parsing_list):\n",
        "        # block is a PaddleOCRVLBlock object, access attributes directly\n",
        "        label = getattr(block, 'label', 'unknown')\n",
        "        content = getattr(block, 'content', '')\n",
        "        \n",
        "        if content:  # Only show blocks with content\n",
        "            label_emoji = {\n",
        "                'doc_title': 'ðŸ“Œ',\n",
        "                'paragraph_title': 'ðŸ“',\n",
        "                'text': 'ðŸ“',\n",
        "                'image': 'ðŸ–¼ï¸',\n",
        "                'table': 'ðŸ“Š',\n",
        "                'vision_footnote': 'ðŸ“Ž'\n",
        "            }.get(label, 'â€¢')\n",
        "            \n",
        "            print(f\"\\n{label_emoji} [{label.upper()}]\")\n",
        "            print(\"-\" * 40)\n",
        "            print(content[:500] + ('...' if len(content) > 500 else ''))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸŽ‰ Congratulations!\n",
        "\n",
        "You have successfully run PaddleOCR-VL on AMD GPU with vLLM backend.\n",
        "\n",
        "### Resources\n",
        "- [PaddleX Documentation](https://paddlepaddle.github.io/PaddleX/)\n",
        "- [PaddleOCR-VL Tutorial](https://github.com/PaddlePaddle/PaddleX)\n",
        "- [AMD ROCm](https://rocm.docs.amd.com/)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
